
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>About | [“Welcome to Hongcen Ye（叶洪岑）’s homepage.”]</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="About" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="https://andyye1999.github.io/" />
<meta property="og:url" content="https://andyye1999.github.io/" />
<meta property="og:site_name" content="[“Welcome to Hongcen Ye（叶洪岑）’s homepage.”]" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="About" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","headline":"About","name":"[“Welcome to Hongcen Ye（叶洪岑）’s homepage.”]","url":"https://andyye1999.github.io/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=b3e4a4daa47f83a7474c6268eaa95beeb8e0e9c4">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="https://zhihaodu.github.io/">Welcome to Hongcen Ye（叶洪岑）’s homepage.</a></h1>
      

      <h2 id="about">About（关于）</h2>

<p>Hi, I’m @andyye1999, a graduate student of Dalian University of Technology This is my homepage  
 I’m interested in speech signal processing, such as aec, ns, anc, agc, Microphone Array Processing, AIcodec and Bone conduction change to air conduction  
 I’m currently learning Active Noise Cancellation, AIcodec and BWE  
 I’m looking to collaborate on deep learning on speech signal processing</p>


<!-- 
<h2 id="publications">Publications（出版物）</h2>

<p>(Note: Most of my papers can be found on arxiv.)</p>

<h3 id="journal--papers">Journal  Papers（期刊论文）</h3>

<ol>
  <li><strong><u>Zhihao Du</u></strong>, Xueliang Zhang, Jiqing Han. A joint framework of denoising autoencoder and generative vocoder for monaural speech enhancement. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020. <a href="https://zhihaodu.github.io/dagv_demo/">View Demos</a></li>
</ol>

<h3 id="conference-papers">Conference Papers（会议论文）</h3>

<ol>
  <li>Mohan Shi, <strong>Zhihao Du</strong>, et al., A Comparative Study on Multichannel Speaker-Attributed Automatic Speech Recognition in Multi-Party Meetings. APSIPA 2023</li>
  <li>Yue Gu, <strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Qian Chen, Jiqing Han, Personality-aware Training based Speaker Adaptation for End-to-end Speech Recognition. INTERSPEECH 2023 <a href="https://zhihaodu.github.io/gu2023pat.pdf">Paper</a></li>
  <li>Mohan Shi, <strong><u>Zhihao Du</u></strong>, Qian Chen, Fan Yu, Yangze Li, Shiliang Zhang, Jie Zhang, Lirong Dai, CASA-ASR: Context-Aware Speaker-Attributed ASR. INTERSPEECH 2023</li>
  <li>Zhifu Gao, Zerui Li, Jiaming Wang, Haoneng Luo, Xian Shi, Mengzhe Chen, Yabin Li, Lingyun Zuo, <strong><u>Zhihao Du</u></strong>, Zhangyu Xiao, Shiliang Zhang, FunASR: A Fundamental End-to-End Speech Recognition Toolkit. INTERSPEECH 2023</li>
  <li>Jiaming Wang*, <strong><u>Zhihao Du*</u></strong>, Shiliang Zhang. TOLD: A Novel Two-stage Overlap-aware Framework for Speaker Diarization. ICASSP 2023 (equal contribution)</li>
  <li><strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Siqi Zheng, Zhijie Yan. Speaker Overlap-aware Neural Diarization for Multi-party Meeting Analysis. EMNLP 2022 (long paper)</li>
  <li>Yuxiao Lin, <strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Fan Yu, Zhou Zhao, Fei Wu, Separate-to-Recognize: Joint Multi-target Speech Separation and Speech Recognition for Speaker-attributed ASR. ISCSLP 2022</li>
  <li>Fan Yu, Shiliang Zhang, Pengcheng Guo, Yuhao Liang, <strong><u>Zhihao Du</u></strong>, et.al. MFCCA: Multi-Frame Cross-Channel attention for multi-speaker ASR in Multi-party meeting scenario. SLT 2022</li>
  <li>Fan Yu, <strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Yuxiao Lin, Lei Xie. A Comparative Study on Speaker-attributed Automatic Speech Recognition in Multi-party Meetings. ICASSP 2022</li>
  <li>Fan Yu, Shiliang Zhang, Pengcheng Guo, Yihui Fu, <strong><u>Zhihao Du</u></strong>, et.al. Summary on the ICASSP 2022 multi-channel multi-party meeting transcription grand challenge. ICASSP 2022</li>
  <li>Fan Yu, Shiliang Zhang, Yihui Fu, Lei Xie, Siqi Zheng, <strong><u>Zhihao Du</u></strong>, et.al. M2MeT: The ICASSP 2022 multi-channel multi-party meeting transcription challenge. ICASSP 2022</li>
  <li>Hongwei Song, Jiqing Han, Shiwen Deng, <strong><u>Zhihao Du</u></strong>. Capturing Temporal Dependencies Through Future Prediction for CNN-Based Audio Classifiers. ICASSP 2021</li>
  <li><strong><u>Zhihao Du</u></strong>, Ming Lei, Jiqing Han, Shiliang Zhang. Pan: Phoneme-aware network for monaural speech enhancement. ICASSP 2020.</li>
  <li><strong><u>Zhihao Du</u></strong>, Ming Lei, Jiqing Han, Shiliang Zhang. Self-Supervised Adversarial Multi-Task Learning for Vocoder-Based Monaural Speech Enhancement. INTERSPEECH 2020</li>
  <li><strong><u>Zhihao Du</u></strong>, Jiqing Han, Xueliang Zhang. Double Adversarial Network Based Monaural Speech Enhancement for Robust Speech Recognition. INTERSPEECH 2020, https://github.com/ZhihaoDU/du2020dan</li>
  <li>Yue Gu, <strong><u>Zhihao Du</u></strong>, Hui Zhang, Xueliang Zhang. An Efficient Joint Training Framework for Robust Small-Footprint Keyword Spotting. ICONIP 2020</li>
  <li>Hongwei Song, Jiqing Han, Shiwen Deng. <strong><u>Zhihao Du</u></strong>. Acoustic scene classification by implicitly identifying distinct sound events, INTERSPEECH 2019</li>
  <li><strong><u>Zhihao Du</u></strong>, Xueliang Zhang, Jiqing Han. Investigation of Monaural Front-End Processing for Robust Speech Recognition Without Retraining or Joint-Training. APSIPA 2019.</li>
</ol>
      
<h3 id="preprints">Preprints（预印本）</h3>

<ol>
  <li><strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Siqi Zheng, Zhijie Yan. Speaker Embedding-aware Neural Diarization for Flexible Number of Speakers with Textual Information. https://arxiv.org/abs/2111.13694.</li>
</ol>

<h3 id="phd-thesis">PhD Thesis（博士论文）</h3>

<p>RESEARCH ON MONAURAL SPEECH ENHANCEMENT BASED ON PRIOR INFORMATION IN DIFFERENT SEMANTIC LEVELS（基于不同语义层级先验信息的
   单通道语音增强方法研究）.</p>

<h2 id="审稿">Reviewer（审稿)</h2>

<ol>
  <li>International Conference on Asian Language Processing (IALP) 2023</li>
  <li>Conference of the International Speech Communication Association (INTERSPEECH) 2023</li>
  <li>International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2023</li>
  <li>International Symposium on Chinese Spoken Language Processing (ISCSLP) 2022</li>
</ol>

<h2 id="opensources">Open sources（开源代码）</h2>
<ol>
  <li>Widely-used speech features, https://github.com/ZhihaoDU/speech_feature_extractor, star 100+</li>
</ol>
  
<h2 id="荣誉">Honors（荣誉）</h2>
<ol>
  <li>哈尔滨工业大学优秀博士论文提名（2021）</li>
  <li>内蒙古自治区优秀毕业生（2015）</li>
  <li>MCM Meritorious Winner</li>
  <li>ACM/ICPC 二等奖</li>
</ol>
      
<h2 id="Organization">Organization（组织）</h2>
<ol>
  <li>IEEE Member</li>
  <li>SIGDAT Member</li>
</ol>

-->
<h2 id="Graduation">Graduation（教育经历）</h2>
<ol>
  <li>Dalian University of Technology 大连理工大学 2021-2024</li>
  <li>新一代电子信息技术   导师：<a href="http://faculty.dlut.edu.cn/Fuliang_Yin/zh_CN/index.htm">殷福亮教授</a> <a href="http://faculty.dlut.edu.cn/chenzhe/zh_CN/index/745511/list/index.htm">陈喆教授</a> </li>
  <li>Hangzhou Dianzi University 杭州电子科技大学 电子信息工程  2017-2021</li>
  
</ol>

<h2 id="contact-me">Contact me（联系我）</h2>

<p>TEL: +86-13777856377</p>

<p>E-mails: as_yhc@163.com.</p>

      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
  </body>
</html>
